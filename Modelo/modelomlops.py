# -*- coding: utf-8 -*-
"""ModeloMLOps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vZjSrAZuSXV9UrhxTJf1TIM3pAFBfjzb
"""

pip install -q pandas scikit-learn joblib palmerpenguins

import pandas as pd
from palmerpenguins import load_penguins
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import joblib

# -----------------------------
# 1. Cargar dataset
# -----------------------------
# Cambia la ruta si hace falta al archivo penguins.csv descargado
#df = pd.read_csv("penguins.csv")
df = load_penguins()

# Ver las primeras filas
print("Shape del dataset:", df.shape)
print(df.head())

# -----------------------------
# 2. Limpieza básica
# -----------------------------
# Quitamos filas con valores faltantes (puedes también imputar si quieres)
df = df.dropna()

# Selección de columnas predictoras y etiqueta (target)
X = df.drop("species", axis=1)
y = df["species"]

# -----------------------------
# 3. Definir preprocesamiento
# -----------------------------
# Columnas categóricas que deben codificarse
cat_cols = ["island", "sex"]

# Columnas numéricas
num_cols = [c for c in X.columns if c not in cat_cols]

# Preprocesador: OneHotEncoder para categóricas
preprocessor = ColumnTransformer(
    transformers=[
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols)
    ],
    remainder="passthrough"  # deja las columnas numéricas sin cambio
)

# -----------------------------
# 4. Pipeline con DecisionTreeClassifier
# -----------------------------
clf = Pipeline(
    steps=[
        ("preprocess", preprocessor),
        ("model", DecisionTreeClassifier(random_state=42))
    ]
)

clfRF = Pipeline(
    steps=[
        ("preprocess", preprocessor),
        ("model", RandomForestClassifier(random_state=42))
    ]
)

# -----------------------------
# 5. Entrenar y evaluar
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Entrenamiento
clf.fit(X_train, y_train)

clfRF.fit(X_train, y_train)

# Predicción y métricas
y_pred = clf.predict(X_test)
print("Accuracy en test:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificación:\n", classification_report(y_test, y_pred))

y_pred = clfRF.predict(X_test)
print("Accuracy en test:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificación:\n", classification_report(y_test, y_pred))

# -----------------------------
# 6. Guardar el modelo
# -----------------------------
model_file = "penguin_decision_tree.pkl"
joblib.dump(clf, model_file)
print(f"\nModelo guardado exitosamente en: {model_file}")

model_file = "penguin_random_forest.pkl"
joblib.dump(clfRF, model_file)
print(f"\nModelo guardado exitosamente en: {model_file}")
